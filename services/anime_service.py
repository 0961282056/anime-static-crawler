from typing import List, Dict, Tuple, Optional
from bs4 import BeautifulSoup
import requests, os, json, hashlib, time, re, logging
import multiprocessing
import cloudinary, cloudinary.uploader, cloudinary.utils
from dotenv import load_dotenv
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from datetime import datetime

# ã€å‡ç´š 1ã€‘å¼•å…¥ Pydantic æ¨¡å‹
from models import Anime
from config import Config

# ------------------------------------------------------
# åˆå§‹åŒ–èˆ‡è¨­å®š
# ------------------------------------------------------
load_dotenv()
logging.basicConfig(level=logging.INFO) 
logger = logging.getLogger(__name__)
logging.getLogger("urllib3.connectionpool").setLevel(logging.ERROR)

CACHE_FILE = os.path.join(os.getcwd(), 'cloudinary_cache.json')

# ------------------------------------------------------
# requests Session & Pool è¨­å®š
# ------------------------------------------------------
pool_size = 5
retry_strategy = Retry(
    total=3, backoff_factor=0.5,
    status_forcelist=[429, 500, 502, 503, 504]
)
adapter = HTTPAdapter(pool_connections=pool_size, pool_maxsize=pool_size,
                      max_retries=retry_strategy)

cloudinary_adapter = HTTPAdapter(pool_connections=4, pool_maxsize=4,
                                 max_retries=retry_strategy)

SEASON_TO_MONTH = Config.SEASON_TO_MONTH
WEEKDAY_MAP = Config.WEEKDAY_MAP

# ------------------------------------------------------
# é€²ç¨‹é–“å…±äº«æ•¸æ“š
# ------------------------------------------------------
session_global = None 
cloudinary_config_global = {} 
manager_lock_global = None
manager_cache_global = None

def init_worker(shared_lock, shared_cache_dict):
    """æ¯å€‹é€²ç¨‹å•Ÿå‹•æ™‚åˆå§‹åŒ–è³‡æº"""
    global session_global, cloudinary_config_global, manager_lock_global, manager_cache_global
    
    manager_lock_global = shared_lock
    manager_cache_global = shared_cache_dict
    
    session_global = requests.Session()
    session_global.mount("http://", adapter)
    session_global.mount("https://", adapter)
    session_global.mount("https://api.cloudinary.com", cloudinary_adapter)
    
    cloudinary_config_global = {
        'cloud_name': os.getenv("CLOUDINARY_CLOUD_NAME"),
        'api_key': os.getenv("CLOUDINARY_API_KEY"),
        'api_secret': os.getenv("CLOUDINARY_API_SECRET"),
        'long_url_signature': True,
        'secure': True
    }
    cloudinary.config(**cloudinary_config_global)
    cloudinary.config(http_client=session_global)
    
    logging.basicConfig(level=logging.INFO)
    logging.getLogger("urllib3.connectionpool").setLevel(logging.ERROR)

# ------------------------------------------------------
# ç°¡æ˜“å¿«å– (JSON)
# ------------------------------------------------------
def load_local_cache() -> Dict:
    if os.path.exists(CACHE_FILE):
        try:
            with open(CACHE_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            logger.error(f"è¼‰å…¥å¿«å–å¤±æ•—: {e}")
            return {}
    return {}

def save_local_cache(data: Dict):
    try:
        filtered_data = {k: v for k, v in data.items() if k.startswith('cloudinary_')}
        with open(CACHE_FILE, 'w', encoding='utf-8') as f:
            json.dump(filtered_data, f, ensure_ascii=False, indent=4) 
    except Exception as e:
        logger.error(f"å„²å­˜å¿«å–å¤±æ•—: {e}")

# ------------------------------------------------------
# è¼”åŠ©å‡½å¼
# ------------------------------------------------------
def parse_date_time(anime: Dict) -> Tuple[int, float]:
    try:
        if anime["premiere_date"] == "ç„¡é¦–æ’­æ—¥æœŸ":
            return 8, float("inf")
        weekday = WEEKDAY_MAP.get(anime["premiere_date"], 7)
        if anime["premiere_time"] == "ç„¡é¦–æ’­æ™‚é–“":
            return weekday, 0.0
        match = re.match(r"(\d{1,2}):(\d{2})", anime["premiere_time"])
        if not match:
            raise ValueError
        hour, minute = int(match.group(1)), int(match.group(2))
        return weekday, hour + minute / 60.0
    except Exception:
        return 7, float("inf")

# ------------------------------------------------------
# Discord é€šçŸ¥ (Rich Notification)
# ------------------------------------------------------
def send_discord_notification(status: str, year: str, season: str, count: int = 0, error_msg: str = ""):
    """ã€å‡ç´š 3ã€‘ç™¼é€æ¼‚äº®çš„ Embed é€šçŸ¥åˆ° Discord"""
    webhook_url = os.getenv("DISCORD_WEBHOOK_URL")
    
    # å¦‚æœæ²’è¨­å®š Webhookï¼Œå°±ç›´æ¥è·³éï¼Œä¸å ±éŒ¯
    if not webhook_url:
        return

    # è¨­å®šé¡è‰² (ç¶ è‰²æˆåŠŸï¼Œç´…è‰²å¤±æ•—)
    color = 3066993 if status == "SUCCESS" else 15158332
    title = "âœ… å‹•ç•«çˆ¬èŸ²æ›´æ–°æˆåŠŸ" if status == "SUCCESS" else "ğŸš¨ å‹•ç•«çˆ¬èŸ²åŸ·è¡Œå¤±æ•—"
    
    description = f"**å­£åº¦**: {year} {season}\n"
    if status == "SUCCESS":
        description += f"**è³‡æ–™ç­†æ•¸**: {count} ç­†\n**ç‹€æ…‹**: å·²æ›´æ–°è‡³ GitHub & Cloudflare"
    else:
        description += f"**éŒ¯èª¤åŸå› **: {error_msg}\nè«‹æª¢æŸ¥ GitHub Actions Logsã€‚"

    payload = {
        "username": "Anime Crawler Bot",
        "avatar_url": "https://cdn-icons-png.flaticon.com/512/4712/4712109.png",
        "embeds": [{
            "title": title,
            "description": description,
            "color": color,
            "footer": {"text": f"åŸ·è¡Œæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"}
        }]
    }
    
    try:
        requests.post(webhook_url, json=payload, timeout=5)
    except Exception as e:
        logger.error(f"Discord é€šçŸ¥ç™¼é€å¤±æ•—: {e}")

# ------------------------------------------------------
# åœ–ç‰‡è™•ç†
# ------------------------------------------------------
def upload_to_cloudinary(image_url: str, anime_name: str) -> str:
    """è™•ç†åœ–ç‰‡ä¸Šå‚³æˆ–å¿«å–å‘½ä¸­"""
    if image_url == "ç„¡åœ–ç‰‡":
        return "ç„¡åœ–ç‰‡"
    
    session = session_global
    local_cache = manager_cache_global 
    
    try:
        response = session.get(image_url, timeout=6)
        response.raise_for_status()
        
        content_hash = hashlib.md5(response.content).hexdigest()
        public_id = f"anime_covers/{content_hash}"
        cloudinary_key = f"cloudinary_{content_hash}"
        
        # æª¢æŸ¥å¿«å–
        with manager_lock_global:
            if cloudinary_key in local_cache:
                return local_cache[cloudinary_key]
        
        # ã€å‡ç´š 2ã€‘ä½¿ç”¨è‡ªå‹•æ ¼å¼ (f_auto) èˆ‡è‡ªå‹•å“è³ª (q_auto) é€²è¡Œ WebP å„ªåŒ–
        upload_result = cloudinary.uploader.upload(
            response.content,
            public_id=public_id, overwrite=True, invalidate=True,
            transformation=[
                {"width": 300, "height": 450, "crop": "limit", "quality": "auto", "fetch_format": "auto"}
            ]
        )
            
        url, _ = cloudinary.utils.cloudinary_url(
            upload_result["public_id"],
            fetch_format="auto", quality="auto", width=300, height=450, crop="limit"
        )
        
        with manager_lock_global:
            local_cache[cloudinary_key] = url
        
        logger.info(f"[UPLOAD] {anime_name} ä¸Šå‚³å®Œæˆ (WebPå„ªåŒ–)")
        return url

    except Exception as e:
        logger.error(f"[ERROR] {anime_name} åœ–ç‰‡è™•ç†å¤±æ•—: {e}")
        return image_url

def worker_process_anime(item_html_str: str) -> Optional[Dict]:
    """Worker: è§£æä¸¦ä½¿ç”¨ Pydantic é©—è­‰è³‡æ–™"""
    try:
        item = BeautifulSoup(item_html_str, "lxml").find("div", class_="CV-search")
        if not item: return None
        
        anime_name_elem = item.find("h3", {"class": "entity_localized_name"})
        anime_name = anime_name_elem.get_text(strip=True) if anime_name_elem else None
        
        premiere_date_elem = item.find("div", {"class": "time_today main_time"})
        premiere_date, premiere_time = None, None
        
        if premiere_date_elem:
            text = premiere_date_elem.get_text(strip=True)
            week_match = re.search(r"æ¯é€±([ä¸€äºŒä¸‰å››äº”å…­æ—¥å¤©])", text)
            if week_match: premiere_date = week_match.group(1)
            time_match = re.search(r"(\d{1,2})æ™‚(\d{1,2})åˆ†", text)
            if time_match: premiere_time = f"{int(time_match.group(1)):02d}:{int(time_match.group(2)):02d}"

        image_tag = item.find("div", {"class": "overflow-hidden anime_cover_image"})
        image_url = image_tag.img["src"] if image_tag and image_tag.img else "ç„¡åœ–ç‰‡"
        
        # åŸ·è¡Œåœ–ç‰‡ä¸Šå‚³
        anime_image_url = upload_to_cloudinary(image_url, anime_name or "æœªçŸ¥") 

        story_elem = item.find("div", {"class": "anime_story"})
        story = story_elem.get_text(strip=True) if story_elem else None
        
        # ã€å‡ç´š 1ã€‘ä½¿ç”¨ Pydantic æ¨¡å‹å»ºç«‹èˆ‡é©—è­‰
        # å¦‚æœç¼ºå°‘å¿…è¦æ¬„ä½ï¼Œæ¨¡å‹æœƒè‡ªå‹•å¡«å…¥é è¨­å€¼ (åœ¨ models.py å®šç¾©)
        anime_obj = Anime(
            bangumi_id=item.get("acgs-bangumi-data-id", "æœªçŸ¥ID"),
            anime_name=anime_name,
            anime_image_url=anime_image_url,
            premiere_date=premiere_date,  # è‹¥ç‚º Noneï¼Œæ¨¡å‹æœƒè½‰ç‚º "ç„¡é¦–æ’­æ—¥æœŸ"
            premiere_time=premiere_time,  # è‹¥ç‚º Noneï¼Œæ¨¡å‹æœƒè½‰ç‚º "ç„¡é¦–æ’­æ™‚é–“"
            story=story                   # è‹¥ç‚º Noneï¼Œæ¨¡å‹æœƒè½‰ç‚º "æš«ç„¡ç°¡ä»‹"
        )
        
        # è½‰å› dict ä¾›å¾ŒçºŒè™•ç†
        return anime_obj.model_dump()

    except Exception as exc:
        logger.warning(f"è™•ç†å¤±æ•—: {exc}")
        return None

# ------------------------------------------------------
# ä¸»çˆ¬èŸ²é‚è¼¯
# ------------------------------------------------------
def fetch_anime_data(year: str, season: str, cache=None) -> List[Dict]:
    """ä¸»å‡½å¼"""
    
    if season not in SEASON_TO_MONTH:
        return [{"error": "å­£ç¯€ç„¡æ•ˆ"}]

    url = f"https://acgsecrets.hk/bangumi/{year}{SEASON_TO_MONTH[season]:02d}/"
    
    with multiprocessing.Manager() as manager:
        try:
            # 1. æŠ“å– HTML
            with requests.Session() as s:
                s.mount("http://", adapter)
                s.mount("https://", adapter)
                response = s.get(url, timeout=10) 
                response.raise_for_status()
            response.encoding = "utf-8"
            
            # 2. è§£æ
            soup = BeautifulSoup(response.text, "lxml")
            anime_items = soup.select("div#acgs-anime-list div.CV-search")
            if not anime_items:
                msg = f"{year} {season} ä¾†æºç¶²ç«™ç„¡è³‡æ–™ (HTMLçµæ§‹æ­£ç¢ºä½†ç„¡é …ç›®)"
                logger.warning(msg)
                # è¦–æƒ…æ³æ±ºå®šæ˜¯å¦ç™¼é€å¤±æ•—é€šçŸ¥ï¼Œé€™è£¡é¸æ“‡ä¸è¦–ç‚ºåš´é‡éŒ¯èª¤
                return []

            item_html_strings = [str(item) for item in anime_items]
            
            # 3. åˆå§‹åŒ–å…±äº«è³‡æº
            shared_lock = manager.Lock()
            shared_cache_dict = manager.dict() 
            shared_cache_dict.update(load_local_cache())
            
            # 4. å¤šé€²ç¨‹è™•ç†
            max_workers = os.cpu_count() or 1
            with multiprocessing.Pool(processes=max_workers, initializer=init_worker, initargs=(shared_lock, shared_cache_dict)) as pool:
                results = pool.map(worker_process_anime, item_html_strings)

            anime_list = [res for res in results if res is not None]
            
            if not anime_list:
                error_msg = f"{year} {season} çˆ¬å–çµæœç‚ºç©º (å¯èƒ½è§£æå¤±æ•—)"
                logger.warning(f"âš ï¸ {error_msg}")
                # ç™¼é€å¤±æ•—é€šçŸ¥
                send_discord_notification("FAILURE", year, season, 0, error_msg)
                return []

            sorted_list = sorted(anime_list, key=parse_date_time)
            
            # 5. å­˜å›å¿«å–
            save_local_cache(dict(shared_cache_dict))
            
            logger.info(f"æˆåŠŸçˆ¬å– {year} {season} å…± {len(sorted_list)} ç­†è³‡æ–™")
            
            # ã€å‡ç´š 3ã€‘ç™¼é€æˆåŠŸé€šçŸ¥ (å¸¶æ•¸æ“š)
            send_discord_notification("SUCCESS", year, season, len(sorted_list))
            
            return sorted_list

        except Exception as e:
            logger.error(f"çˆ¬å–å¤±æ•—: {e}")
            # ç™¼é€å¤±æ•—é€šçŸ¥
            send_discord_notification("FAILURE", year, season, 0, str(e))
            return [{"error": f"ç³»çµ±éŒ¯èª¤: {str(e)}"}]

def get_current_season(month: int) -> str:
    if 1 <= month <= 3: return "å†¬"
    if 4 <= month <= 6: return "æ˜¥"
    if 7 <= month <= 9: return "å¤"
    return "ç§‹"