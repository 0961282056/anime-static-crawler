name: Scheduled Anime Crawler

on:
  schedule:
    # æ¯å¤© UTC 17:00 (å°ç£æ™‚é–“ 01:00)
    - cron: '0 17 * * *'
  workflow_dispatch:

jobs:
  crawl-and-update:
    runs-on: ubuntu-latest
    permissions:
      contents: write

    steps:
      - name: â¬‡ï¸ Checkout Repository
        uses: actions/checkout@v4

      - name: ğŸ Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      # ä¿®æ­£ 1: ç§»é™¤ working-directoryï¼Œç›´æ¥åœ¨æ ¹ç›®éŒ„å®‰è£ä¾è³´
      - name: âš™ï¸ Install dependencies
        run: |
          pip install -r requirements.txt

      # ä¿®æ­£ 2: ç§»é™¤ working-directoryï¼Œç›´æ¥åŸ·è¡Œçˆ¬èŸ²è…³æœ¬
      - name: ğŸ•·ï¸ Run Crawler
        env:
          CLOUDINARY_CLOUD_NAME: ${{ secrets.CLOUDINARY_CLOUD_NAME }}
          CLOUDINARY_API_KEY: ${{ secrets.CLOUDINARY_API_KEY }}
          CLOUDINARY_API_SECRET: ${{ secrets.CLOUDINARY_API_SECRET }}
          BUILD_ONLY: false
        run: |
          python generate_static.py

      # ä¿®æ­£ 3: ä¿®æ”¹ git add è·¯å¾‘ (ç§»é™¤ 'å‹•ç•«è³‡è¨Šçˆ¬èŸ²/' å‰ç¶´)
      - name: ğŸ’¾ Commit and Push new data
        run: |
          git config --global user.name 'GitHub Action Crawler'
          git config --global user.email 'action@github.com'
          
          # æ³¨æ„ï¼šé€™è£¡ç›´æ¥åŠ å…¥ dist è³‡æ–™å¤¾èˆ‡å¿«å–æª”
          git add dist/data/*.json
          git add cloudinary_cache.json
          
          # æª¢æŸ¥æ˜¯å¦æœ‰è®Šæ›´ï¼Œæœ‰è®Šæ›´æ‰ Commit
          if git diff --staged --quiet; then
            echo "No changes to commit."
          else
            git commit -m "ğŸ¤– Auto-update anime data & cache [skip ci]"
            git push
            echo "âœ… Data pushed to GitHub. Cloudflare Pages should trigger build now."
          fi